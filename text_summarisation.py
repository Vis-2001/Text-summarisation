# -*- coding: utf-8 -*-
"""Text summarisation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1beyxboaYCTS8Wirb8V33pD1MizRsgu5K

this part of programming ia to remove all the stop words
"""

import nltk
nltk.download('popular')
from nltk.corpus import stopwords
s=stopwords.words('english')
def rem(st):
  st_tok=st.split(' ')
  nost=[]
  for i in st_tok:
    if i not in s:
      nost.append(i)
  return nost
st=input("Enter a article:") 
sts=st.lower()
sen=sts.split(".")
token=[]
for i in sen:
  t=rem(i)
  for j in t:
    token.append(j)
token=list(set(token))
for i in token:
  print(i)

"""this part of text is to get the root word of key words"""

from nltk.stem import WordNetLemmatizer
w=WordNetLemmatizer()
lemitised=[]
for i in token:
  wd=w.lemmatize(i)
  lemitised.append(wd)
lemit_final=list(set(lemitised))
for i in lemit_final:
  print(i)

"""this part of program is to find the tf of the article"""

def tf(st):
  wds=st.split(" ")
  pts=[]
  for i in lemit_final:
    count=0
    for j in wds:
      if i==j:
        count+=1
    m=count/float(len(wds))
    pts.append(m)
  return pts
tfs=[]
for i in sen:
  tfs.append(tf(i))

"""this part of code is to get idf """

import math as m
def idf():
  pts=[]
  le=len(sen)
  for i in lemit_final:
    cnt=0
    for j in sen:
      if i in j:
        cnt+=1
    pts.append(m.log(le/(float(cnt)+1)))
  return pts
idfs=idf()
print(idfs)

"""the following segment returns the tfidf value of the document"""

tfitf=[]
for i in tfs:
  spl=[]
  z=len(lemit_final)
  for j in range (0,z):
    spl.append(i[j]*idfs[j])
  tfitf.append(spl)
for i in tfitf:
  print(i)

"""the following part returns the summary of your document"""

su=[]
for i in tfitf:
  sq=0
  for j in i:
    sq+=j
  su.append(sq)
avg=sum(su)/len(su)
z=len(su)
print("Summary of your atricle is:")
for i in range(0,z):
  if (su[i]>avg):
    print(sen[i])